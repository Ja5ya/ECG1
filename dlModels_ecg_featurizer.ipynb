{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUybmemQcR3v"
      },
      "source": [
        "# ECG data analysis\n",
        "\n",
        "Using the PTB-XL data, this notebook:\n",
        "1. Loads the data\n",
        "2. Explores the metadata,\n",
        "3. Visualizes the signal data in interactive figures\n",
        "4. Summarized a theory and literature review.\n",
        "5. Extracts wave peaks from the 1D signals and visualizes these\n",
        "6. explores the useage of a codebase for multilabel diagnostic classification, to expand on in future instance.\n",
        "\n",
        "**Note:** on the first run, the second call will make the runtime crash to downgrade fastai to an older version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLsC-CByDld8",
        "outputId": "251579cc-acc8-408a-f847-b07d58493c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.0+cu117\n",
            "0.15.1+cu117\n"
          ]
        }
      ],
      "source": [
        "# Import torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oT_1MOmHubMH"
      },
      "outputs": [],
      "source": [
        "## In this cell, set 'show_all_figs = False'\n",
        "## if you want to save RAM for model training:\n",
        "show_all_figs = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2_VBRkReUGkA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1DeAop4ySOI7"
      },
      "outputs": [],
      "source": [
        "## Import the libraries we will use in our initial exploration:\n",
        "from pathlib import Path\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "# from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import plotly.graph_objects as go\n",
        "# import plotly.express as px\n",
        "import wfdb\n",
        "import ast\n",
        "\n",
        "## Allow \"hot-reloading\" of modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWnAr54qlC5L"
      },
      "source": [
        "## 1. Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R90T9YqBcQDW",
        "outputId": "9d43e0b3-a992-4e1e-d0b4-6cacca7f0c3c"
      },
      "outputs": [],
      "source": [
        "data_filepath = 'D:/Test Jupyter/ECG-Classfier-main/data/ecg_featurizer/'\n",
        "\n",
        "Y_train = np.load(data_filepath + 'X_train.npy')\n",
        "Z_train = np.load(data_filepath + 'y_train.npy', allow_pickle=True)\n",
        "Y_test = np.load(data_filepath + 'X_test.npy')\n",
        "Z_test = np.load(data_filepath + 'y_test.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0aIjTqp3M_s",
        "outputId": "dba00015-7890-4bc6-f2e6-9e6d35488496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17441, 26) (17441, 5)\n",
            "(4396, 26) (4396, 5)\n"
          ]
        }
      ],
      "source": [
        "print(Y_train.shape, Z_train.shape)\n",
        "print(Y_test.shape,  Z_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4HJKqyROJAm",
        "outputId": "69bb182c-3fa8-416a-f4c7-932c3386ecf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 9.40000000e-01,  1.49071198e-02,  5.96700000e-01,  5.69632338e-02,\n",
              "        9.44444444e-01,  5.47947911e-02,  6.74054292e-02,  3.12024046e-02,\n",
              "        9.40000000e-01,  9.20144916e-02,  2.20656609e-02,  7.62759502e-02,\n",
              "        9.37500000e-01,  1.39194109e-02, -4.70345236e-02,  1.70020277e-02,\n",
              "        9.26250000e-01,  5.65547301e-02, -5.86236777e-02,  8.38237741e-03,\n",
              "        1.17777800e+01,  4.26296000e+00,             nan,             nan,\n",
              "        1.30000000e+01,  2.64575000e+00])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handle Nan values and standardize feature variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Instantiate the imputer\n",
        "imputer = SimpleImputer(strategy='mean')  # You can choose 'median' or 'most_frequent' as well\n",
        "\n",
        "# Fit the imputer on your training data and transform it\n",
        "Y_train = imputer.fit_transform(Y_train)\n",
        "\n",
        "# Apply the same imputer to your test data\n",
        "Y_test = imputer.transform(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 9.40000000e-01,  1.49071198e-02,  5.96700000e-01,  5.69632338e-02,\n",
              "        9.44444444e-01,  5.47947911e-02,  6.74054292e-02,  3.12024046e-02,\n",
              "        9.40000000e-01,  9.20144916e-02,  2.20656609e-02,  7.62759502e-02,\n",
              "        9.37500000e-01,  1.39194109e-02, -4.70345236e-02,  1.70020277e-02,\n",
              "        9.26250000e-01,  5.65547301e-02, -5.86236777e-02,  8.38237741e-03,\n",
              "        1.17777800e+01,  4.26296000e+00,  3.48918572e+01,  1.37843482e+01,\n",
              "        1.30000000e+01,  2.64575000e+00])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fEO1a_Q3CIC0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and test data\n",
        "Y_train = scaler.fit_transform(Y_train)\n",
        "Y_test = scaler.transform(Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 5.68295978e-01, -4.80387092e-01, -2.92598160e-01, -4.17777843e-01,\n",
              "        5.82545553e-01, -1.51812181e-01,  1.07468846e+00, -1.71371722e-02,\n",
              "        1.66127909e-01, -1.58598559e-01, -6.81270856e-01,  5.38051595e-01,\n",
              "        3.61249090e-01, -4.76503536e-01,  3.93540206e-01, -4.01501546e-01,\n",
              "        4.75191114e-01, -9.24219300e-02,  7.31744955e-01, -5.58001923e-01,\n",
              "       -9.34994491e-02,  1.65922693e-01, -2.66692127e-13, -1.19894673e-13,\n",
              "       -6.76955342e-01,  2.27724702e-01])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aQLwhA0xKt55"
      },
      "outputs": [],
      "source": [
        "# Convert your data to PyTorch tensors\n",
        "# Convert NumPy arrays to PyTorch tensors with the appropriate data types\n",
        "Y_train = torch.FloatTensor(Y_train)\n",
        "# Converting DataFrame to a NumPy array and then to Pytorch tensor\n",
        "# Z_train = Z_train.to_numpy()  # Convert Z_train DataFrame to a NumPy array\n",
        "# Convert the NumPy array to a PyTorch tensor\n",
        "Z_train = torch.FloatTensor(Z_train)\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors with the appropriate data types\n",
        "Y_test = torch.FloatTensor(Y_test)\n",
        "# Converting DataFrame to a NumPy array and then to Pytorch tensor\n",
        "# Z_test = Z_test.to_numpy()  # Convert Z_test DataFrame to a NumPy array\n",
        "# Convert the NumPy array to a PyTorch tensor\n",
        "Z_test = torch.FloatTensor(Z_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7gTZcFhRgM_",
        "outputId": "72e312c4-f2dc-4a1a-eb20-b2f035ebe128"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([17441, 26])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1prNZGgUF_f",
        "outputId": "b77d0ada-f3b8-4bbd-da0e-362088aa2591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4396, 26])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C0WJvRaGhSn",
        "outputId": "b4078c60-7c52-490f-83e8-86b6fcf43748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "emSZrxGQxmls"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, Y, Z):\n",
        "        self.Y = torch.Tensor(Y)  # Input data\n",
        "        self.Z = torch.Tensor(Z)  # Multilabel class labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.Y[idx], self.Z[idx]\n",
        "\n",
        "# Create custom datasets and dataloaders\n",
        "train_dataset = CustomDataset(Y_train, Z_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = CustomDataset(Y_test, Z_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8YqGBx4jYRv",
        "outputId": "93a97553-87b3-4704-f85e-4cfd22932369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 0., 0.])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for train_images, train_labels in train_loader:\n",
        "    sample_image = train_images[0]    # Reshape them according to your needs.\n",
        "    sample_label = train_labels[0]\n",
        "\n",
        "# sample_image\n",
        "sample_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h09xP0uiMcoJ",
        "outputId": "d7dde65c-e0f1-42ce-d48c-2126365fb735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000249D470AB60>, <torch.utils.data.dataloader.DataLoader object at 0x00000249D4709330>)\n",
            "Length of the train_loader: 546 batches of 32...\n",
            "Length of the test_loader: 138 batches of 32...\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "# Let's check out what we have created\n",
        "print(f\"DataLoaders: {train_loader, test_loader}\")\n",
        "print(f\"Length of the train_loader: {len(train_loader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"Length of the test_loader: {len(test_loader)} batches of {BATCH_SIZE}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvTKhq5mM-qs",
        "outputId": "74682f4f-f85c-4ef5-99b4-6aa220765c65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 26]), torch.Size([32, 5]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out what's inside training data loader\n",
        "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
        "train_features_batch.shape, train_labels_batch.shape\n",
        "# test_features_batch, test_labels_batch = next(iter(test_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Start creating models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9xJe14amJvRf"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\Test Jupyter\\ECG-Classfier-main\\code\\dlModels_ecg_featurizer.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m input_size \u001b[39m=\u001b[39m \u001b[39m26\u001b[39m  \u001b[39m# Number of input features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m output_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m  \u001b[39m# Number of output classes (labels)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m MultilabelClassifier(input_size, output_size)\u001b[39m.\u001b[39;49mto(device)\n",
            "File \u001b[1;32mc:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[1;32mc:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[1;32mc:\\Users\\ROG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the neural network model\n",
        "class MultilabelClassifier(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(MultilabelClassifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),  # Input layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),  # Hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_size),  # Output layer\n",
        "            nn.Sigmoid()  # Sigmoid activation for multilabel classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = 26  # Number of input features\n",
        "output_size = 5  # Number of output classes (labels)\n",
        "model = MultilabelClassifier(input_size, output_size).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AkR65mQJvOw",
        "outputId": "dac171d9-f1f7-4fba-c6c5-37abce2ddb8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultilabelClassifier(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=26, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=5, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LDcfU2rJvMi",
        "outputId": "49431dcc-c016-4064-b7d8-dcafe64d216f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 26])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pass a random image through model\n",
        "# rand_image_tensor = torch.randn(size=(1,12,500))\n",
        "rand_image_tensor = torch.randn(size=(1,26))\n",
        "rand_image_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxoBgWmJvJH",
        "outputId": "066fd101-55f8-4cf4-c62e-e91bc74a6b81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.5297, 0.4630, 0.4784, 0.5201, 0.4288]]], device='cuda:0',\n",
              "       grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Pass image through model\n",
        "model(rand_image_tensor.unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HxD8mCBR1DOl"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start:float,\n",
        "                     end:float,\n",
        "                     device:torch.device = None):\n",
        "  \"\"\"Prints differnce between start and end time\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time: .3f} seconds\")\n",
        "  return total_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define train and test steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VZiUQUC-1P-8"
      },
      "outputs": [],
      "source": [
        "def train_step(model, data_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == labels.argmax(dim=1)).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    train_accuracy = (correct_predictions / total_samples) * 100\n",
        "    train_loss /= len(data_loader)\n",
        "\n",
        "    # print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    return train_loss, train_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GgIabBcb1Rw9"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device = device):\n",
        "    \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
        "    test_loss, correct_predictions, total_samples = 0, 0, 0\n",
        "\n",
        "    # Put the model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off gradients and inference mode context manager\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_loader:\n",
        "            # Send the data to the target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y).item()\n",
        "\n",
        "            # 3. Calculate accuracy (accumulatively)\n",
        "            _, predicted = torch.max(test_pred, 1)\n",
        "            correct_predictions += (predicted == y.argmax(dim=1)).sum().item()\n",
        "            # correct_predictions += (predicted == y).sum().item()\n",
        "            total_samples += y.size(0)\n",
        "\n",
        "        # Calculate test loss and accuracy\n",
        "        test_loss /= len(data_loader)\n",
        "        test_accuracy = (correct_predictions / total_samples) * 100\n",
        "\n",
        "        # print(f\"Test Loss: {test_loss:.5f} | Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
        "\n",
        "        return test_loss, test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Nne0tOdpQ_T"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, loss_fn, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    # correct_predictions = 0\n",
        "    correct_samples = 0\n",
        "    total_samples = 0\n",
        "    all_true_labels = []\n",
        "    all_pred_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predicted_labels = (outputs >= threshold).float()  # Apply threshold (e.g., 0.5)\n",
        "\n",
        "            # Calculate correct predictions for the batch\n",
        "            # batch_correct_predictions = (predicted_labels == labels).sum().item()\n",
        "            batch_correct_samples = (predicted_labels == labels).all(dim=1).sum().item()\n",
        "\n",
        "\n",
        "            # Count the total number of labels in the batch\n",
        "            batch_total_samples = labels.sum().item()\n",
        "\n",
        "            # correct_predictions += batch_correct_predictions\n",
        "            correct_samples += batch_correct_samples\n",
        "            # total_samples += inputs.size(0)\n",
        "            total_samples += batch_total_samples\n",
        "\n",
        "\n",
        "            all_true_labels.extend(labels.cpu().numpy())\n",
        "            all_pred_scores.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "        test_loss /= len(data_loader)\n",
        "        # test_accuracy = (correct_predictions / total_samples) * 100\n",
        "        test_accuracy = (correct_samples / total_samples) * 100\n",
        "\n",
        "    return test_loss, test_accuracy, all_true_labels, all_pred_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cCrDgnRvAK__"
      },
      "outputs": [],
      "source": [
        "def evaluate_model2(model, data_loader, loss_fn, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct_samples = 0\n",
        "    total_samples = 0\n",
        "    all_true_labels = []\n",
        "    all_pred_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predicted_labels = (outputs >= threshold).float()  # Apply threshold (e.g., 0.5)\n",
        "\n",
        "            # Check if all labels for each sample are predicted correctly\n",
        "            batch_correct_samples = (predicted_labels == labels).all(dim=1).sum().item()\n",
        "\n",
        "            correct_samples += batch_correct_samples\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_true_labels.extend(labels.cpu().numpy())\n",
        "            all_pred_scores.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "        test_loss /= len(data_loader)\n",
        "        test_accuracy = (correct_samples / total_samples) * 100\n",
        "\n",
        "    return test_loss, test_accuracy, all_true_labels, all_pred_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Call model and print evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Q7eO5FR4CHwg"
      },
      "outputs": [],
      "source": [
        "# loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                            lr = 0.001)#optimize all bias and weight, i.e. everything in model_2.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "379a02ab8a7a468582a62ec8c30c4aa1",
            "0222e1d276fa40778055b2b508eb181c",
            "e36fda9e35b441a69788d20f9104a429",
            "0c121489a81447be989ba04d55154b96",
            "a4438182f7444fe9b1130ee5ae507b05",
            "7a7a6f171fc64313a242afa1d85fdeec",
            "fe3c211c146046d6a3a82019edc13904",
            "f4a729b40bc9498fbfd680537720f05b",
            "cc16ce12e17c48f4af99f81bf750b982",
            "8a41e940e04548439478bc0dcd84ad1d",
            "913030aae0da43459e24ed9dc7f2888f"
          ]
        },
        "id": "5zro5XEvpiXb",
        "outputId": "8df8dc38-c9d6-47f6-9ea0-f301f8f1b285"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04b2cc5e95d649e59ec4be039425f786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:0\n",
            "-----------\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\Test Jupyter\\ECG-Classfier-main\\code\\dlModels_ecg_featurizer.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch:\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-----------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train_step(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                                             data_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                                             loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                                             optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                                             device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     train_accuracies\u001b[39m.\u001b[39mappend(train_accuracy)\n",
            "\u001b[1;32md:\\Test Jupyter\\ECG-Classfier-main\\code\\dlModels_ecg_featurizer.ipynb Cell 35\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m total_samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Test%20Jupyter/ECG-Classfier-main/code/dlModels_ecg_featurizer.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, multilabel_confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "class_names = ['NORM', 'MI', 'STTC', 'CD', 'HYP']\n",
        "\n",
        "def plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss', marker='o')\n",
        "    plt.plot(test_losses, label='Test Loss', marker='o')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy', marker='o')\n",
        "    plt.plot(test_accuracies, label='Test Accuracy', marker='o')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Initialize empty lists to store training and testing metrics\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "all_true_labels = []\n",
        "all_pred_scores = []\n",
        "\n",
        "# Training and testing loop\n",
        "epochs = 25\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch:{epoch}\\n-----------\")\n",
        "    train_loss, train_accuracy = train_step(model=model,\n",
        "                                            data_loader=train_loader,\n",
        "                                            loss_fn=loss_fn,\n",
        "                                            optimizer=optimizer,\n",
        "                                            device=device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "    test_loss, test_accuracy, true_labels, pred_scores = evaluate_model2(model=model,\n",
        "                                                                       data_loader=test_loader,\n",
        "                                                                       loss_fn=loss_fn,\n",
        "                                                                       device=device)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    all_true_labels.extend(true_labels)\n",
        "    all_pred_scores.extend(pred_scores)\n",
        "\n",
        "# Plot training and testing metrics\n",
        "plot_metrics(train_losses, test_losses, train_accuracies, test_accuracies)\n",
        "\n",
        "# Convert predicted scores to binary predictions based on a threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "all_pred_labels = (np.array(all_pred_scores) >= threshold).astype(int)\n",
        "\n",
        "# Calculate and print precision, recall, F1-score, confusion matrix\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "class_report = classification_report(all_true_labels, all_pred_labels, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVjMtVGppiRh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eji-lm6EpiO4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oWJkqR_i6fZx",
        "9zYJaryKzw_s"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0222e1d276fa40778055b2b508eb181c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7a6f171fc64313a242afa1d85fdeec",
            "placeholder": "​",
            "style": "IPY_MODEL_fe3c211c146046d6a3a82019edc13904",
            "value": "100%"
          }
        },
        "0c121489a81447be989ba04d55154b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a41e940e04548439478bc0dcd84ad1d",
            "placeholder": "​",
            "style": "IPY_MODEL_913030aae0da43459e24ed9dc7f2888f",
            "value": " 25/25 [1:08:14&lt;00:00, 163.46s/it]"
          }
        },
        "379a02ab8a7a468582a62ec8c30c4aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0222e1d276fa40778055b2b508eb181c",
              "IPY_MODEL_e36fda9e35b441a69788d20f9104a429",
              "IPY_MODEL_0c121489a81447be989ba04d55154b96"
            ],
            "layout": "IPY_MODEL_a4438182f7444fe9b1130ee5ae507b05"
          }
        },
        "7a7a6f171fc64313a242afa1d85fdeec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a41e940e04548439478bc0dcd84ad1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913030aae0da43459e24ed9dc7f2888f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4438182f7444fe9b1130ee5ae507b05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc16ce12e17c48f4af99f81bf750b982": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e36fda9e35b441a69788d20f9104a429": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a729b40bc9498fbfd680537720f05b",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc16ce12e17c48f4af99f81bf750b982",
            "value": 25
          }
        },
        "f4a729b40bc9498fbfd680537720f05b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe3c211c146046d6a3a82019edc13904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

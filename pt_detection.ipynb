{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPijrT6UrXM"
      },
      "source": [
        "# Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YonaFF2cU1lm",
        "outputId": "989b84e7-f128-432e-e673-8fd0fce660db"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.signal as signal\n",
        "import pywt\n",
        "\n",
        "import wfdb\n",
        "import os\n",
        "\n",
        "from biosppy import storage\n",
        "from biosppy.signals import ecg\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7DwCxRbmS8r"
      },
      "source": [
        "# PQRST window detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PwvG9SD6mXO0"
      },
      "outputs": [],
      "source": [
        "def r_peaks_detection(signal, sampling_rate=250.):\n",
        "  out = ecg.ecg(signal=signal, sampling_rate=sampling_rate, show=False)\n",
        "  return out[\"rpeaks\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mxZv_Y5WmaQV"
      },
      "outputs": [],
      "source": [
        "def qs_peaks_detection(signal, r_peaks, qs_range=20):\n",
        "  qs_peaks = []\n",
        "  for r_peak in r_peaks:\n",
        "    if r_peak - qs_range >= 0:\n",
        "      q_signal_slice = signal[r_peak - qs_range: r_peak]\n",
        "      q_peak = np.argmin(q_signal_slice, axis=0) + r_peak - qs_range\n",
        "      qs_peaks.append(q_peak)\n",
        "    if r_peak + qs_range <= len(signal):\n",
        "      s_signal_slice = signal[r_peak: r_peak + qs_range]\n",
        "      s_peak = np.argmin(s_signal_slice, axis=0) + r_peak\n",
        "      qs_peaks.append(s_peak)\n",
        "  return qs_peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VOThiRl-memo"
      },
      "outputs": [],
      "source": [
        "def pt_peaks_detection(signal, r_peaks, alpha=0, beta=0, coef=1):\n",
        "  p_min = -20\n",
        "  p_max = (-40 - beta) * coef\n",
        "  t_min = 20\n",
        "  t_max = (50 + alpha) * coef # or do not do +1 -- to try\n",
        "  pt_peaks = []\n",
        "  for r_peak in r_peaks:\n",
        "    if r_peak + p_max >= 0:\n",
        "      p_signal_slice = signal[int(r_peak + p_max):int(r_peak + p_min)]\n",
        "      p_peak = np.argmax(p_signal_slice, axis=0) + r_peak + p_max\n",
        "      pt_peaks.append(p_peak)\n",
        "    if r_peak + t_max <= len(signal):\n",
        "      t_signal_slice = signal[int(r_peak+t_min):int(r_peak+t_max)]\n",
        "      t_peak = np.argmax(t_signal_slice, axis=0) + r_peak + t_min\n",
        "      pt_peaks.append(t_peak)\n",
        "  return pt_peaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MymjiQRAmkEE"
      },
      "outputs": [],
      "source": [
        "def pqrst_detection(signal, qs_drop=False, r_drop=False, alpha=0, beta=0, coef=1):\n",
        "  peaks = []\n",
        "  r_peaks = r_peaks_detection(signal)\n",
        "  if not qs_drop:\n",
        "    peaks.extend(qs_peaks_detection(signal, r_peaks))\n",
        "  if not r_drop:\n",
        "    peaks.extend(r_peaks)\n",
        "  peaks.extend(pt_peaks_detection(signal, r_peaks, alpha=alpha, beta=beta, coef=coef))\n",
        "  return sorted(peaks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzLaz0NvZvyy"
      },
      "source": [
        "# Dataset cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-LuX3o00Z1JL"
      },
      "outputs": [],
      "source": [
        "def del_duplic(symbols, samples):\n",
        "  clean_symbols = []\n",
        "  clean_samples = []\n",
        "  index = 0\n",
        "  while index < len(symbols) - 1:\n",
        "    if symbols[index] != symbols[index+1]:\n",
        "      clean_symbols.append(symbols[index])\n",
        "      clean_samples.append(samples[index])\n",
        "    index+=1\n",
        "  clean_symbols.append(symbols[len(symbols)-1])\n",
        "  clean_samples.append(len(symbols)-1)\n",
        "  return clean_symbols, clean_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CO2ptDx9Z21a"
      },
      "outputs": [],
      "source": [
        "def clear_rng(clean_samples, clean_symbols):\n",
        "  true_peaks = []\n",
        "  true_symbols = []\n",
        "\n",
        "  for index, (peak_index, peak) in enumerate(zip(clean_samples, clean_symbols)):\n",
        "    if peak != \"(\" and peak != \")\":\n",
        "      true_peaks.append(peak_index)\n",
        "      true_symbols.append(peak)\n",
        "  return true_peaks, true_symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S0hXHGqMZ88j"
      },
      "outputs": [],
      "source": [
        "def pnt_seq(true_peaks, true_symbols):\n",
        "  indexes = []\n",
        "  i = 1\n",
        "  while i <= len(true_symbols)-2:\n",
        "    if true_symbols[i] == \"N\":\n",
        "      if true_symbols[i-1] == \"p\" and true_symbols[i+1] == \"t\":\n",
        "        indexes.append(i-1)\n",
        "        indexes.append(i)\n",
        "        indexes.append(i+1)\n",
        "    i+=1\n",
        "  peaks = [true_peaks[i] for i in indexes]\n",
        "  symbols = [true_symbols[i] for i in indexes]\n",
        "  return peaks, symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "41m4BLVOZ9id"
      },
      "outputs": [],
      "source": [
        "def dataset_prep(symbol, sample):\n",
        "  symbols = symbol\n",
        "  samples = sample\n",
        "  clean_symbols, clean_samples = del_duplic(symbols, samples)\n",
        "  true_peaks, true_symbols = clear_rng(clean_samples, clean_symbols)\n",
        "  peaks, symbols = pnt_seq(true_peaks,true_symbols)\n",
        "  return peaks, symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ePGjj1d2aDi7"
      },
      "outputs": [],
      "source": [
        "def sync_peaks(prt_peaks, peaks):\n",
        "  window_ind = []\n",
        "  ind = []\n",
        "  find_j = -2\n",
        "\n",
        "  for i in range(1, len(peaks),3):\n",
        "    find = False\n",
        "    j = find_j + 3\n",
        "    while not find and j <= len(prt_peaks)-2:\n",
        "      if abs(peaks[i] - prt_peaks[j]) < 20:\n",
        "        window_ind += [prt_peaks[j-1], prt_peaks[j], prt_peaks[j+1]]\n",
        "        ind += [peaks[i-1], peaks[i], peaks[i+1]]\n",
        "        find_j = j\n",
        "        find = True\n",
        "      else:\n",
        "        j += 3\n",
        "  # peaks = ind\n",
        "  # window_peaks = window_ind\n",
        "  drops = len(peaks) - len(ind)\n",
        "  if drops > 0:\n",
        "    print(f\"When syncing missed values was found: {drops} ({drops*100/len(peaks)}%)\")\n",
        "  return ind, window_ind"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i91bEs50U6Dj"
      },
      "source": [
        "# Comparing manual and auto detection from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "frFB7cGwYy4f"
      },
      "outputs": [],
      "source": [
        "input_directory = '/content/physionet.org/files/qtdb/1.0.0/'\n",
        "input_files = []\n",
        "for f in os.listdir(input_directory):\n",
        "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith(\".\") and f.lower().endswith(\"q1c\"):\n",
        "        input_files.append(f[:-4])\n",
        "num_files = len(input_files)\n",
        "\n",
        "data_filepath = 'D:/Test Jupyter/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl/'\n",
        "\n",
        "X = np.load(data_filepath + 'raw100.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "pW0LIxFKZYmt",
        "outputId": "8474d8a0-512c-4392-c3f0-59952e05ec25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When syncing missed values was found: 6 (4.0%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 48 (55.172413793103445%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 9 (6.0%)\n",
            "When syncing missed values was found: 45 (50.0%)\n",
            "When syncing missed values was found: 3 (1.408450704225352%)\n",
            "When syncing missed values was found: 54 (60.0%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 60 (66.66666666666667%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 18 (21.428571428571427%)\n",
            "When syncing missed values was found: 12 (18.181818181818183%)\n",
            "When syncing missed values was found: 6 (11.764705882352942%)\n",
            "When syncing missed values was found: 9 (10.0%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 90 (88.23529411764706%)\n",
            "When syncing missed values was found: 18 (10.344827586206897%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 90 (90.9090909090909%)\n",
            "When syncing missed values was found: 12 (8.0%)\n",
            "When syncing missed values was found: 42 (46.666666666666664%)\n",
            "When syncing missed values was found: 42 (29.78723404255319%)\n",
            "When syncing missed values was found: 6 (6.666666666666667%)\n",
            "When syncing missed values was found: 12 (13.333333333333334%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 27 (18.0%)\n",
            "When syncing missed values was found: 15 (16.666666666666668%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 6 (6.666666666666667%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 3 (3.225806451612903%)\n",
            "When syncing missed values was found: 63 (70.0%)\n",
            "When syncing missed values was found: 24 (26.666666666666668%)\n",
            "When syncing missed values was found: 42 (46.666666666666664%)\n",
            "When syncing missed values was found: 3 (2.7777777777777777%)\n",
            "When syncing missed values was found: 84 (90.3225806451613%)\n",
            "When syncing missed values was found: 3 (3.3333333333333335%)\n",
            "When syncing missed values was found: 15 (16.666666666666668%)\n",
            "When syncing missed values was found: 69 (76.66666666666667%)\n"
          ]
        }
      ],
      "source": [
        "peaks_p_all = []\n",
        "peaks_n_all = []\n",
        "peaks_t_all = []\n",
        "\n",
        "peaks_p_auto_all = []\n",
        "peaks_n_auto_all = []\n",
        "peaks_t_auto_all = []\n",
        "\n",
        "true_peaks_all = []\n",
        "true_peaks_all_auto = []\n",
        "\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "  record_atr_auto = wfdb.rdann(temp_file_path, 'pu0')\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "  true_peaks_auto, true_symbols_auto = dataset_prep(record_atr_auto.symbol, record_atr_auto.sample)\n",
        "\n",
        "  true_p, true_p_auto = sync_peaks(true_peaks_auto, true_peaks)\n",
        "\n",
        "  true_peaks_all.extend(true_p)\n",
        "  true_peaks_all_auto.extend(true_p_auto)\n",
        "\n",
        "  peaks_p = [val for i,val in enumerate(true_p) if i%3 == 0]\n",
        "  peaks_n = [val for i,val in enumerate(true_p) if (i-1)%3 == 0]\n",
        "  peaks_t = [val for i,val in enumerate(true_p) if (i-2)%3 == 0]\n",
        "\n",
        "  peaks_p_auto = [val for i,val in enumerate(true_p_auto) if i%3 == 0]\n",
        "  peaks_n_auto = [val for i,val in enumerate(true_p_auto) if (i-1)%3 == 0]\n",
        "  peaks_t_auto = [val for i,val in enumerate(true_p_auto) if (i-2)%3 == 0]\n",
        "\n",
        "  peaks_p_all.extend(peaks_p)\n",
        "  peaks_n_all.extend(peaks_n)\n",
        "  peaks_t_all.extend(peaks_t)\n",
        "\n",
        "  peaks_p_auto_all.extend(peaks_p_auto)\n",
        "  peaks_n_auto_all.extend(peaks_n_auto)\n",
        "  peaks_t_auto_all.extend(peaks_t_auto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "zJscRuQpjm_-",
        "outputId": "55b858b2-9913-4f25-cc63-3113e30e5655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for dataset's automatically determined waveform boundary measurements:  5.379580220562078\n",
            "MAE score for dataset's automatically determined waveform boundary measurements p peaks:  3.4368552116684454\n",
            "MAE score for dataset's automatically determined waveform boundary measurements r peaks:  2.8616150836001424\n",
            "MAE score for dataset's automatically determined waveform boundary measurements t peaks:  9.840270366417645\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements:  {mean_absolute_error(true_peaks_all, true_peaks_all_auto)}\")\n",
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_auto_all)}\")\n",
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements r peaks:  {mean_absolute_error(peaks_n_all, peaks_n_auto_all)}\")\n",
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_auto_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "DC8qsrStrd1u",
        "outputId": "d76f64d2-9e89-48b7-a1db-2db6f9ab07a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for dataset's automatically determined waveform boundary measurements p peaks:  3.4368552116684454\n",
            "MAE score for dataset's automatically determined waveform boundary measurements t peaks:  9.840270366417645\n",
            "Accuracy for dataset's automatically determined waveform boundary measurements p peaks:  84 %\n",
            "Accuracy for dataset's automatically determined waveform boundary measurements t peaks:  68 %\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_auto_all)}\")\n",
        "print(f\"MAE score for dataset's automatically determined waveform boundary measurements t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_auto_all)}\")\n",
        "\n",
        "p = 0\n",
        "for p_, p_pred in zip(peaks_p_all, peaks_p_auto_all):\n",
        " if abs(p_ - p_pred) <= 5:\n",
        "   p+=1\n",
        "print(\"Accuracy for dataset's automatically determined waveform boundary measurements p peaks: \",int((p * 100)/len(peaks_p_all)) ,\"%\")\n",
        "\n",
        "t = 0\n",
        "for t_, t_pred in zip(peaks_t_all, peaks_t_auto_all):\n",
        " if abs(t_ - t_pred) <= 5:\n",
        "   t+=1\n",
        "print(\"Accuracy for dataset's automatically determined waveform boundary measurements t peaks: \",int((t * 100)/len(peaks_t_all)) ,\"%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LgEBquplhHS"
      },
      "source": [
        "# Comparing manual and my detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XHPTZ24yLpkV",
        "outputId": "aafe4d69-44d9-44b3-e014-535fd10ddd2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When syncing missed values was found: 3 (2.0%)\n"
          ]
        }
      ],
      "source": [
        "peaks_p_all = []\n",
        "peaks_n_all = []\n",
        "peaks_t_all = []\n",
        "\n",
        "peaks_p_window_all = []\n",
        "peaks_n_window_all = []\n",
        "peaks_t_window_all = []\n",
        "\n",
        "true_peaks_all = []\n",
        "true_peaks_all_window = []\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "  l_range = 0\n",
        "  r_range = len(record.p_signal)+1\n",
        "\n",
        "  data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "  peaks = pqrst_detection(data_slice,qs_drop=True, alpha=0)\n",
        "\n",
        "  true_p, true_p_wind = sync_peaks(peaks, true_peaks)\n",
        "  true_peaks_all.extend(true_p)\n",
        "  true_peaks_all_window.extend(true_p_wind)\n",
        "\n",
        "  peaks_p = [val for i,val in enumerate(true_p) if i%3 == 0]\n",
        "  peaks_p_all.extend(peaks_p)\n",
        "  peaks_n = [val for i,val in enumerate(true_p) if (i-1)%3 == 0]\n",
        "  peaks_n_all.extend(peaks_n)\n",
        "  peaks_t = [val for i,val in enumerate(true_p) if (i-2)%3 == 0]\n",
        "  peaks_t_all.extend(peaks_t)\n",
        "\n",
        "  peaks_p_wind = [val for i,val in enumerate(true_p_wind) if i%3 == 0]\n",
        "  peaks_p_window_all.extend(peaks_p_wind)\n",
        "  peaks_n_wind = [val for i,val in enumerate(true_p_wind) if (i-1)%3 == 0]\n",
        "  peaks_n_window_all.extend(peaks_n_wind)\n",
        "  peaks_t_wind = [val for i,val in enumerate(true_p_wind) if (i-2)%3 == 0]\n",
        "  peaks_t_window_all.extend(peaks_t_wind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JCUCvLNEm6nG",
        "outputId": "095eeaad-7085-4205-a3a2-7f10682bf397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for window algorithm p peaks:  7.692982456140351\n",
            "MAE score for window algorithm t peaks:  28.594611528822057\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for window algorithm p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_all)}\")\n",
        "print(f\"MAE score for window algorithm t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Pm-L8t63sXtV",
        "outputId": "9cb5e5b7-c68b-4af8-896d-b03017594dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for window algorithm p peaks:  7.692982456140351\n",
            "MAE score for window algorithm t peaks:  28.594611528822057\n",
            "Accuracy for window algorithm p peaks:  60 %\n",
            "Accuracy for window algorithm t peaks:  5 %\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for window algorithm p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_all)}\")\n",
        "print(f\"MAE score for window algorithm t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_all)}\")\n",
        "\n",
        "p = 0\n",
        "for p_, p_pred in zip(peaks_p_all, peaks_p_window_all):\n",
        " if abs(p_ - p_pred) <= 5:\n",
        "   p+=1\n",
        "print(\"Accuracy for window algorithm p peaks: \",int((p * 100)/len(peaks_p_all)) ,\"%\")\n",
        "\n",
        "t = 0\n",
        "for t_, t_pred in zip(peaks_t_all, peaks_t_window_all):\n",
        " if abs(t_ - t_pred) <= 5:\n",
        "   t+=1\n",
        "print(\"Accuracy for window algorithm t peaks: \",int((t * 100)/len(peaks_t_all)) ,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP-O9_OjoE6a"
      },
      "source": [
        "# Finding best apha/beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kZoimcHRQ39v",
        "outputId": "b6e362b9-a336-4059-ca2c-58d62236dfa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 198 (92.95774647887323%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 30 (35.714285714285715%)\n",
            "When syncing missed values was found: 15 (22.727272727272727%)\n",
            "When syncing missed values was found: 75 (83.33333333333333%)\n",
            "When syncing missed values was found: 75 (83.33333333333333%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 171 (98.27586206896552%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 21 (23.333333333333332%)\n",
            "When syncing missed values was found: 150 (100.0%)\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "When syncing missed values was found: 63 (70.0%)\n",
            "When syncing missed values was found: 78 (86.66666666666667%)\n",
            "When syncing missed values was found: 90 (96.7741935483871%)\n",
            "When syncing missed values was found: 90 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "alpha_list = np.arange(-5,40,0.5)\n",
        "beta_list = np.arange(-15,50,0.5)\n",
        "\n",
        "peaks_p_all = []\n",
        "peaks_n_all = []\n",
        "peaks_t_all = []\n",
        "\n",
        "peaks_p_window_ab_all = []\n",
        "peaks_n_window_ab_all = []\n",
        "peaks_t_window_ab_all = []\n",
        "\n",
        "true_peaks_all = []\n",
        "true_peaks_all_window_ab = []\n",
        "\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "  mae_t = []\n",
        "  if len(true_peaks) > 3:\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    for index, alpha in enumerate(alpha_list):\n",
        "      true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "      peaks = pqrst_detection(data_slice,qs_drop=True, alpha=alpha)\n",
        "      true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "      peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "\n",
        "      window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "\n",
        "      mae_t.append(mean_absolute_error(peaks_t, window_peaks_t))\n",
        "\n",
        "    alpha = alpha_list[np.argmin(mae_t)]\n",
        "\n",
        "    mae_p = []\n",
        "\n",
        "    true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "    for index, beta in enumerate(beta_list):\n",
        "      peaks = pqrst_detection(data_slice,qs_drop=True, beta=beta )\n",
        "      true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "\n",
        "      peaks_p = [val for i,val in enumerate(true_peaks) if i%3 == 0]\n",
        "\n",
        "      window_peaks_p = [val for i,val in enumerate(peaks) if i%3 == 0]\n",
        "      if len(window_peaks_p) > 1:\n",
        "        mae_p.append(mean_absolute_error(peaks_p, window_peaks_p))\n",
        "\n",
        "    beta = beta_list[np.argmin(mae_p)]\n",
        "\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    peaks = pqrst_detection(data_slice,qs_drop=True, alpha=alpha, beta=beta)\n",
        "\n",
        "    true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "    true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "    true_peaks_all.extend(true_p)\n",
        "    true_peaks_all_window.extend(true_p_wind)\n",
        "\n",
        "    peaks_p = [val for i,val in enumerate(true_peaks) if i%3 == 0]\n",
        "    peaks_p_all.extend(peaks_p)\n",
        "    peaks_n = [val for i,val in enumerate(true_peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_all.extend(peaks_n)\n",
        "    peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_all.extend(peaks_t)\n",
        "\n",
        "    window_peaks_p = [val for i,val in enumerate(peaks) if i%3 == 0]\n",
        "    peaks_p_window_ab_all.extend(window_peaks_p)\n",
        "    window_peaks_n = [val for i,val in enumerate(peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_window_ab_all.extend(window_peaks_n)\n",
        "    window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_window_ab_all.extend(window_peaks_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "9WUgKtQo4MUi",
        "outputId": "80e08f15-186e-4ac6-8565-35b1c84e8d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for window method with best alpha/beta p peaks:  3.6259398496240602\n",
            "MAE score for window method with best alpha/beta t peaks:  8.166353383458647\n",
            "Accuracy for window method with best alpha/beta p peaks:  85 %\n",
            "Accuracy for window method with best alpha/beta t peaks:  69 %\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for window method with best alpha/beta p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_ab_all)}\")\n",
        "print(f\"MAE score for window method with best alpha/beta t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_ab_all)}\")\n",
        "\n",
        "p = 0\n",
        "for p_, p_pred in zip(peaks_p_all, peaks_p_window_ab_all):\n",
        " if abs(p_ - p_pred) <= 5:\n",
        "   p+=1\n",
        "print(\"Accuracy for window method with best alpha/beta p peaks: \",int((p * 100)/len(peaks_p_all)) ,\"%\")\n",
        "\n",
        "t = 0\n",
        "for t_, t_pred in zip(peaks_t_all, peaks_t_window_ab_all):\n",
        " if abs(t_ - t_pred) <= 5:\n",
        "   t+=1\n",
        "print(\"Accuracy for window method with best alpha/beta t peaks: \",int((t * 100)/len(peaks_t_all)) ,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL0rF5pL6r9s"
      },
      "source": [
        "# Adaptive alpha/beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzO9VTCap70y"
      },
      "outputs": [],
      "source": [
        "def rr_pt_detection(signal, alpha=0, beta=0, coef=1):\n",
        "  pt_peaks = []\n",
        "  out = ecg.ecg(signal=signal, sampling_rate=250., show=False)\n",
        "  hr = out[\"heart_rate\"]\n",
        "  mean_hr = np.mean(hr)\n",
        "  r_peaks = out[\"rpeaks\"]\n",
        "  for i in range(len(hr)-1):\n",
        "    coef = hr[i] / mean_hr\n",
        "    p_min = -20\n",
        "    p_max = int((-40 - beta) * coef)\n",
        "    t_min = 20\n",
        "    t_max = int((50 + alpha) * coef)\n",
        "\n",
        "    if i == 0 and r_peaks[i] + p_max >= 0 :\n",
        "      p_min = -20\n",
        "      p_max = (-40 - beta)\n",
        "      t_min = 20\n",
        "      t_max = (50 + alpha)\n",
        "      p_signal_slice = signal[int(r_peaks[i] + p_max):int(r_peaks[i] + p_min)]\n",
        "      p_peak = np.argmax(p_signal_slice, axis=0) + r_peaks[i] + p_max\n",
        "      pt_peaks.append(int(p_peak))\n",
        "\n",
        "    p_signal_slice = signal[int(r_peaks[i+1] + p_max):int(r_peaks[i+1] + p_min)]\n",
        "    if len(p_signal_slice) > 1:\n",
        "      p_peak = np.argmax(p_signal_slice, axis=0) + r_peaks[i+1] + p_max\n",
        "      pt_peaks.append(int(p_peak))\n",
        "    t_signal_slice = signal[int(r_peaks[i]+t_min):int(r_peaks[i]+t_max)]\n",
        "    if len(t_signal_slice) > 1:\n",
        "      t_peak = np.argmax(t_signal_slice, axis=0) + r_peaks[i] + t_min\n",
        "      pt_peaks.append(int(t_peak))\n",
        "\n",
        "  p_min = -20\n",
        "  p_max = (-40 - beta)\n",
        "  t_min = 20\n",
        "  t_max = (50 + alpha)\n",
        "  if r_peaks[len(r_peaks)-1] + t_max <= len(signal):\n",
        "    t_signal_slice = signal[int(r_peaks[len(r_peaks)-1]+t_min):int(r_peaks[len(r_peaks)-1]+t_max)]\n",
        "    t_peak = np.argmax(t_signal_slice, axis=0) + r_peaks[len(r_peaks)-1] + t_min\n",
        "    pt_peaks.append(t_peak)\n",
        "\n",
        "  pt_peaks.extend(list(r_peaks))\n",
        "  return sorted(pt_peaks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jsxGg-YHWFgp",
        "outputId": "198c41c8-a687-4c5c-8cd7-d3f126443682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 / 105\n",
            "1 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "2 / 105\n",
            "When syncing missed values was found: 150 (100.0%)\n",
            "When syncing missed values was found: 99 (66.0%)\n",
            "3 / 105\n",
            "4 / 105\n",
            "5 / 105\n",
            "6 / 105\n",
            "When syncing missed values was found: 90 (96.7741935483871%)\n",
            "7 / 105\n",
            "8 / 105\n",
            "9 / 105\n",
            "When syncing missed values was found: 60 (66.66666666666667%)\n",
            "10 / 105\n",
            "11 / 105\n",
            "12 / 105\n",
            "13 / 105\n",
            "14 / 105\n",
            "15 / 105\n",
            "16 / 105\n",
            "17 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "18 / 105\n",
            "When syncing missed values was found: 60 (66.66666666666667%)\n",
            "19 / 105\n",
            "20 / 105\n",
            "21 / 105\n",
            "When syncing missed values was found: 171 (98.27586206896552%)\n",
            "When syncing missed values was found: 174 (100.0%)\n",
            "22 / 105\n",
            "23 / 105\n",
            "When syncing missed values was found: 75 (83.33333333333333%)\n",
            "When syncing missed values was found: 60 (66.66666666666667%)\n",
            "24 / 105\n",
            "25 / 105\n",
            "26 / 105\n",
            "When syncing missed values was found: 15 (22.727272727272727%)\n",
            "27 / 105\n",
            "28 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "29 / 105\n",
            "When syncing missed values was found: 198 (92.95774647887323%)\n",
            "30 / 105\n",
            "31 / 105\n",
            "32 / 105\n",
            "When syncing missed values was found: 21 (23.333333333333332%)\n",
            "33 / 105\n",
            "34 / 105\n",
            "When syncing missed values was found: 102 (68.0%)\n",
            "35 / 105\n",
            "36 / 105\n",
            "37 / 105\n",
            "38 / 105\n",
            "39 / 105\n",
            "40 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "41 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "42 / 105\n",
            "43 / 105\n",
            "44 / 105\n",
            "45 / 105\n",
            "46 / 105\n",
            "47 / 105\n",
            "48 / 105\n",
            "49 / 105\n",
            "50 / 105\n",
            "51 / 105\n",
            "52 / 105\n",
            "53 / 105\n",
            "When syncing missed values was found: 30 (35.714285714285715%)\n",
            "54 / 105\n",
            "55 / 105\n",
            "When syncing missed values was found: 90 (96.7741935483871%)\n",
            "56 / 105\n",
            "57 / 105\n",
            "58 / 105\n",
            "59 / 105\n",
            "60 / 105\n",
            "61 / 105\n",
            "62 / 105\n",
            "63 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "64 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "65 / 105\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 3 (2.0%)\n",
            "When syncing missed values was found: 9 (6.0%)\n",
            "66 / 105\n",
            "67 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "68 / 105\n",
            "69 / 105\n",
            "70 / 105\n",
            "71 / 105\n",
            "72 / 105\n",
            "73 / 105\n",
            "74 / 105\n",
            "75 / 105\n",
            "76 / 105\n",
            "77 / 105\n",
            "78 / 105\n",
            "79 / 105\n",
            "80 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "81 / 105\n",
            "82 / 105\n",
            "83 / 105\n",
            "84 / 105\n",
            "85 / 105\n",
            "86 / 105\n",
            "87 / 105\n",
            "88 / 105\n",
            "89 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "90 / 105\n",
            "91 / 105\n",
            "92 / 105\n",
            "93 / 105\n",
            "94 / 105\n",
            "When syncing missed values was found: 90 (100.0%)\n",
            "95 / 105\n",
            "96 / 105\n",
            "97 / 105\n",
            "98 / 105\n",
            "99 / 105\n",
            "100 / 105\n",
            "When syncing missed values was found: 78 (86.66666666666667%)\n",
            "101 / 105\n",
            "When syncing missed values was found: 75 (83.33333333333333%)\n",
            "102 / 105\n",
            "103 / 105\n",
            "When syncing missed values was found: 63 (70.0%)\n",
            "104 / 105\n"
          ]
        }
      ],
      "source": [
        "alpha_list = np.arange(-5,40,1)\n",
        "beta_list = np.arange(-15,50,1)\n",
        "\n",
        "peaks_p_all = []\n",
        "peaks_n_all = []\n",
        "peaks_t_all = []\n",
        "\n",
        "peaks_p_window_ab_adapt_all = []\n",
        "peaks_n_window_ab_adapt_all = []\n",
        "peaks_t_window_ab_adapt_all = []\n",
        "\n",
        "true_peaks_all = []\n",
        "true_peaks_all_window_ab_adapt = []\n",
        "\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "  print(temp_file_index,\"/\", len(input_files))\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "  mae_t = []\n",
        "\n",
        "  if len(true_peaks) > 3:\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    for index, alpha in enumerate(alpha_list):\n",
        "      true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "      peaks = pqrst_detection(data_slice,qs_drop=True, alpha=alpha)\n",
        "      true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "      peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "\n",
        "      window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "      if len(window_peaks_t) > 1:\n",
        "        mae_t.append(mean_absolute_error(peaks_t, window_peaks_t))\n",
        "      else: mae_t.append(9999999)\n",
        "\n",
        "    alpha = alpha_list[np.argmin(mae_t)]\n",
        "\n",
        "    mae_p = []\n",
        "\n",
        "    true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "    for index, beta in enumerate(beta_list):\n",
        "      peaks = pqrst_detection(data_slice,qs_drop=True, beta=beta )\n",
        "      true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "\n",
        "      peaks_p = [val for i,val in enumerate(true_peaks) if i%3 == 0]\n",
        "\n",
        "      window_peaks_p = [val for i,val in enumerate(peaks) if i%3 == 0]\n",
        "      if len(window_peaks_p) >  1:\n",
        "        mae_p.append(mean_absolute_error(peaks_p, window_peaks_p))\n",
        "      else:\n",
        "        mae_p.append(9999999)\n",
        "\n",
        "    beta = beta_list[np.argmin(mae_p)]\n",
        "\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    prt_peaks = rr_pt_detection(data_slice, alpha=alpha, beta=beta)\n",
        "\n",
        "    true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "    true_peaks, peaks = sync_peaks(prt_peaks, true_peaks)\n",
        "\n",
        "    peaks_p = [val for i,val in enumerate(true_peaks) if i%3 == 0]\n",
        "    peaks_p_all.extend(peaks_p)\n",
        "    peaks_n = [val for i,val in enumerate(true_peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_all.extend(peaks_n)\n",
        "    peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_all.extend(peaks_t)\n",
        "\n",
        "    window_peaks_p = [val for i,val in enumerate(peaks) if i%3 == 0]\n",
        "    peaks_p_window_ab_adapt_all.extend(window_peaks_p)\n",
        "    window_peaks_n = [val for i,val in enumerate(peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_window_ab_adapt_all.extend(window_peaks_n)\n",
        "    window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_window_ab_adapt_all.extend(window_peaks_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "RWGl2e7hxqqU",
        "outputId": "1a546daf-cff5-43b1-c24f-f195fe99b1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for window method with a/b and coef p peaks:  7.656603773584906\n",
            "MAE score for window method with a/b and coef r peaks:  3.2332761578044598\n",
            "MAE score for window method with a/b and coef t peaks:  12.651114922813036\n"
          ]
        }
      ],
      "source": [
        "# print(f\"MAE score for window method with a/b and coef:  {mean_absolute_error(true_peaks_all, true_peaks_all_window_ab_adapt)}\")\n",
        "print(f\"MAE score for window method with a/b and coef p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_ab_adapt_all)}\")\n",
        "print(f\"MAE score for window method with a/b and coef r peaks:  {mean_absolute_error(peaks_n_all, peaks_n_window_ab_adapt_all)}\")\n",
        "print(f\"MAE score for window method with a/b and coef t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_ab_adapt_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "M_tSZhZlpNBf",
        "outputId": "b8cdd605-228c-4652-9aa3-e35b749824ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE score for window method with a/b and coef p peaks:  7.656603773584906\n",
            "MAE score for window method with a/b and coef t peaks:  12.651114922813036\n",
            "Accuracy for window method with a/b and coef p peaks:  81 %\n",
            "Accuracy for window method with a/b and coef t peaks:  26 %\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE score for window method with a/b and coef p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_ab_adapt_all)}\")\n",
        "print(f\"MAE score for window method with a/b and coef t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_ab_adapt_all)}\")\n",
        "\n",
        "p = 0\n",
        "for p_, p_pred in zip(peaks_p_all, peaks_p_window_ab_adapt_all):\n",
        " if abs(p_ - p_pred) <= 5:\n",
        "   p+=1\n",
        "print(\"Accuracy for window method with a/b and coef p peaks: \",int((p * 100)/len(peaks_p_all)) ,\"%\")\n",
        "\n",
        "t = 0\n",
        "for t_, t_pred in zip(peaks_t_all, peaks_p_window_ab_adapt_all):\n",
        " if abs(t_ - t_pred) <= 5:\n",
        "   t+=1\n",
        " print(\"Accuracy for window method with a/b and coef t peaks: \",int((t * 100)/len(peaks_t_all)) ,\"%\")\n",
        "# print(\"Accuracy for window method with a/b and coef t peaks: \",26 ,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E0tb9Z-yN0g"
      },
      "source": [
        "# Creating dataset for regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz1KYEyGznAV"
      },
      "outputs": [],
      "source": [
        "def get_heart_rate(beats=None, sampling_rate=250.):\n",
        "\n",
        "    if beats is None:\n",
        "        raise TypeError(\"Please specify the input beat indices.\")\n",
        "\n",
        "    if len(beats) < 2:\n",
        "        raise ValueError(\"Not enough beats to compute heart rate.\")\n",
        "\n",
        "\n",
        "    ts = beats[1:]\n",
        "    hr = sampling_rate * (60. / np.diff(beats))\n",
        "\n",
        "    indx = [i for i,val in enumerate(hr) if val>=40 and val <=200]\n",
        "    ts = [ts[i] for i in indx]\n",
        "    hr = [hr[i] for i in indx]\n",
        "\n",
        "    return ts, hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm4hmNt-yYrz"
      },
      "outputs": [],
      "source": [
        "def regr_dataset_prep(true_peaks):\n",
        "  true_peaks_sync = []\n",
        "  ranges = []\n",
        "  true_r_peaks = [val for i,val in enumerate(true_peaks) if (i-1)%3 == 0]\n",
        "  ts, hr = get_heart_rate(true_r_peaks)\n",
        "  j=4\n",
        "  for i in range(len(ts)):\n",
        "    found = False\n",
        "    while not found:\n",
        "      if true_peaks[j] == ts[i]:\n",
        "        range_ = [true_peaks[j-2] - true_peaks[j-3], true_peaks[j] - true_peaks[j-1]]\n",
        "        true_peaks_sync.append(true_peaks[j-1])\n",
        "        true_peaks_sync.append(true_peaks[j])\n",
        "        true_peaks_sync.append(true_peaks[j+1])\n",
        "        ranges.append(range_)\n",
        "        found = True\n",
        "      j+=3\n",
        "  if len(ts) != len(ranges):\n",
        "    print(\"Error\")\n",
        "  return hr, ts, ranges, true_peaks_sync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFBccxEXz6wy"
      },
      "outputs": [],
      "source": [
        "input_directory = '/content/physionet.org/files/qtdb/1.0.0/'\n",
        "input_files = []\n",
        "for f in os.listdir(input_directory):\n",
        "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith(\".\") and f.lower().endswith(\"q1c\"):\n",
        "        input_files.append(f[:-4])\n",
        "num_files = len(input_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "YKtsrWT6zumh",
        "outputId": "f29e70dd-e9ef-41f7-aa5c-44f054e7a00a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-5b31148da32d>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for temp_file_index, temp_file in enumerate(input_files[]):\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "  l_range = 0\n",
        "  r_range = len(record.p_signal)+1\n",
        "  data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "  if len(true_peaks) > 6:\n",
        "    hr, ts, ranges, true_peaks = regr_dataset_prep(true_peaks)\n",
        "\n",
        "    rt = [i[0] for i in ranges]\n",
        "    pr = [i[1] for i in ranges]\n",
        "\n",
        "    rt_alpha = [i-70 for i in rt]\n",
        "    pr_alpha = [i-20 for i in pr]\n",
        "\n",
        "    X.extend(hr)\n",
        "    y.extend(rt_alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Ny7CeGJC0amz",
        "outputId": "6b5c42f8-62f9-4c9f-90ca-5f5c4cc27bca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'hr')"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(X, y, alpha=0.7, color=\"b\")\n",
        "plt.ylabel(\"PR len in samples\")\n",
        "plt.xlabel(\"hr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsVqVk4P0tnK"
      },
      "outputs": [],
      "source": [
        "X = np.array(X).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewTYI32J0xxu"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor(n_estimators=200, random_state=100)\n",
        "model_rf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF1b1r__02fH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "y_pred = model_rf.predict(X)\n",
        "mean_squared_error(y, y_pred, squared=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwgGQlSe0691"
      },
      "outputs": [],
      "source": [
        "r2_score(y, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DVNQ7HC1JV-"
      },
      "source": [
        "# Evaluatind regression model on detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ8Xrrxe3VJv"
      },
      "outputs": [],
      "source": [
        "def rr_pt_detection(signal, model, alpha=0, beta=0, coef=1):\n",
        "  pt_peaks = []\n",
        "  out = ecg.ecg(signal=signal, sampling_rate=250., show=False)\n",
        "  hr = out[\"heart_rate\"]\n",
        "  mean_hr = np.mean(hr)\n",
        "  r_peaks = out[\"rpeaks\"]\n",
        "\n",
        "  for i in range(len(hr)-1):\n",
        "    coef = hr[i] / mean_hr\n",
        "    p_min = -20\n",
        "    p_max = int((-40 - model.predict(np.array(hr[i]).reshape(-1,1))) * coef)\n",
        "    t_min = 20\n",
        "    t_max = int((50 + alpha) * coef)\n",
        "\n",
        "    if i == 0 and r_peaks[i] + p_max >= 0 :\n",
        "      p_min = -20\n",
        "      p_max = (-40 - model.predict(np.array(mean_hr).reshape(-1,1)))\n",
        "      p_signal_slice = signal[int(r_peaks[i] + p_max):int(r_peaks[i] + p_min)]\n",
        "      if len(p_signal_slice) > 1:\n",
        "        p_peak = np.argmax(p_signal_slice, axis=0) + r_peaks[i] + p_max\n",
        "        pt_peaks.append(int(p_peak))\n",
        "\n",
        "    p_signal_slice = signal[int(r_peaks[i+1] + p_max):int(r_peaks[i+1] + p_min)]\n",
        "    if len(p_signal_slice) > 1:\n",
        "      p_peak = np.argmax(p_signal_slice, axis=0) + r_peaks[i+1] + p_max\n",
        "      pt_peaks.append(int(p_peak))\n",
        "    t_signal_slice = signal[int(r_peaks[i]+t_min):int(r_peaks[i]+t_max)]\n",
        "    if len(t_signal_slice) > 1:\n",
        "      t_peak = np.argmax(t_signal_slice, axis=0) + r_peaks[i] + t_min\n",
        "      pt_peaks.append(int(t_peak))\n",
        "\n",
        "  t_min = 20\n",
        "  t_max = (50 + alpha)\n",
        "  if r_peaks[len(r_peaks)-1] + t_max <= len(signal):\n",
        "    t_signal_slice = signal[int(r_peaks[len(r_peaks)-1]+t_min):int(r_peaks[len(r_peaks)-1]+t_max)]\n",
        "    t_peak = np.argmax(t_signal_slice, axis=0) + r_peaks[len(r_peaks)-1] + t_min\n",
        "    pt_peaks.append(t_peak)\n",
        "\n",
        "  pt_peaks.extend(list(r_peaks))\n",
        "  return sorted(pt_peaks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NHuuTChIUXe"
      },
      "outputs": [],
      "source": [
        "alpha_list = np.arange(-5,40,1)\n",
        "beta_list = np.arange(-15,50,1)\n",
        "\n",
        "peaks_p_all = []\n",
        "peaks_n_all = []\n",
        "peaks_t_all = []\n",
        "\n",
        "peaks_p_window_ab_pred_all = []\n",
        "peaks_n_window_ab_pred_all = []\n",
        "peaks_t_window_ab_pred_all = []\n",
        "\n",
        "true_peaks_all = []\n",
        "true_peaks_all_window_ab_pred = []\n",
        "\n",
        "for temp_file_index, temp_file in enumerate(input_files):\n",
        "  print(temp_file_index,\"/\", len(input_files))\n",
        "  temp_file_path = os.path.join(input_directory, temp_file)\n",
        "  record_atr = wfdb.rdann(temp_file_path, 'q1c')\n",
        "  record = wfdb.rdrecord(temp_file_path, channels=[0])\n",
        "\n",
        "  l_range = 0\n",
        "  r_range = len(record.p_signal)+1\n",
        "  data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "\n",
        "  true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "  mae_t = []\n",
        "\n",
        "  if len(true_peaks) > 3:\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    for index, alpha in enumerate(alpha_list):\n",
        "      true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "      peaks = pqrst_detection(data_slice,qs_drop=True, alpha=alpha)\n",
        "      true_peaks, peaks = sync_peaks(peaks, true_peaks)\n",
        "      peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "\n",
        "      window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "      if len(window_peaks_t) > 1:\n",
        "        mae_t.append(mean_absolute_error(peaks_t, window_peaks_t))\n",
        "      else: mae_t.append(9999999)\n",
        "\n",
        "    alpha = alpha_list[np.argmin(mae_t)]\n",
        "\n",
        "    l_range = 0\n",
        "    r_range = len(record.p_signal)+1\n",
        "\n",
        "    data_slice = np.ndarray.flatten(record.p_signal[l_range:r_range])\n",
        "    prt_peaks = rr_pt_detection(data_slice,model=model_rf, alpha=alpha, beta=0)\n",
        "\n",
        "    true_peaks, true_symbols = dataset_prep(record_atr.symbol, record_atr.sample)\n",
        "\n",
        "    true_peaks, peaks = sync_peaks(prt_peaks, true_peaks)\n",
        "    true_peaks_all_window_ab_pred.extend(peaks)\n",
        "    true_peaks_all.extend(true_peaks)\n",
        "\n",
        "    peaks_p = [val for i,val in enumerate(true_peaks) if i%3 == 0]\n",
        "    peaks_p_all.extend(peaks_p)\n",
        "    peaks_n = [val for i,val in enumerate(true_peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_all.extend(peaks_n)\n",
        "    peaks_t = [val for i,val in enumerate(true_peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_all.extend(peaks_t)\n",
        "\n",
        "    window_peaks_p = [val for i,val in enumerate(peaks) if i%3 == 0]\n",
        "    peaks_p_window_ab_pred_all.extend(window_peaks_p)\n",
        "    window_peaks_n = [val for i,val in enumerate(peaks) if (i-1)%3 == 0]\n",
        "    peaks_n_window_ab_pred_all.extend(window_peaks_n)\n",
        "    window_peaks_t = [val for i,val in enumerate(peaks) if (i-2)%3 == 0]\n",
        "    peaks_t_window_ab_pred_all.extend(window_peaks_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYhy9F-J5Okm"
      },
      "outputs": [],
      "source": [
        "print(f\"MAE score for window method with a/b and coef:  {mean_absolute_error(true_peaks_all, true_peaks_all_window_ab_pred)}\")\n",
        "print(f\"MAE score for window method with a/b and coef p peaks:  {mean_absolute_error(peaks_p_all, peaks_p_window_ab_pred_all)}\")\n",
        "print(f\"MAE score for window method with a/b and coef r peaks:  {mean_absolute_error(peaks_n_all, peaks_n_window_ab_pred_all)}\")\n",
        "print(f\"MAE score for window method with a/b and coef t peaks:  {mean_absolute_error(peaks_t_all, peaks_t_window_ab_pred_all)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7cbfd1d91e931c0236c69ad29887a2c26b755b4556e62a00b7b645232bfb04d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
